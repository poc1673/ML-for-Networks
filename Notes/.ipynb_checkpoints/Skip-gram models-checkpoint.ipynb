{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Embeddings and Skip Gram Examples\n",
    "\n",
    "**Purpose:** - To explore embedding methods used in label prediction for social networks. This will include a short exposition on the relation of natural language processing to network analysis.\n",
    "\n",
    "**Introduction-** Node embedding methods are a commonly used method for node classification for social networks. This modeling method employs a feature engineering method call skip-gram modeling to represent the relationship of each node in the network in $N$ dimensional vector space. This vector can be thought of as a low dimensional representation of each node. Nodes which are more closely associated with one another will be clustered more closely together in our vector representation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Root in natural language processing\n",
    "\n",
    "This method draws from research in natural language processing where we try to anticipate nearby words based on a corpus used to build the model. Consider the following example system:\n",
    "> The Guadeloupe amazon is a hypothetical extinct species of parrot that is thought to have been endemic to the Lesser Antillean island region of Guadeloupe. Described by 17th- and 18th-century writers, it is thought to have been related to, or possibly the same as, the extant imperial amazon. \n",
    "\n",
    "In natural language processing, one strategy we can use is to define a window of size $w$. These will be used to define an association of words. For example, if we use a window of 3 words we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    " \n",
    "\n",
    "text_example = \"The Guadeloupe amazon is a hypothetical extinct species of parrot that is thought to have been endemic to the Lesser Antillean island region of Guadeloupe. Described by 17th- and 18th-century writers, it is thought to have been related to, or possibly the same as, the extant imperial amazon.\"\n",
    "text_example = text_example.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04512674,  0.02591044,  0.03332372],\n",
       "       [ 0.00830823, -0.03147123, -0.00134744],\n",
       "       [ 0.02704053, -0.03413739, -0.03112757]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(1000, 3)\n",
    "result = embedding_layer(tf.constant([1,2,3]))\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to find a way of representing each of these words. This often involves just coding each word to a number due to brevity. After coding each words into a number, we define a window, $w$ to hold each word association. Below, we define the mapping *to* the number. Afterwards, we will define the mapping back. Finally, we translate out original sentence into the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 4, 9, 21, 8, 19, 17, 31, 24, 26, 32, 21, 34, 35, 18, 13, 15, 35, 33, 6, 2, 22, 28, 24, 5, 3, 14, 0, 11, 1, 37, 23, 21, 34, 35, 18, 13, 29, 36, 25, 27, 33, 30, 12, 33, 16, 20, 10]\n"
     ]
    }
   ],
   "source": [
    "grams = np.unique(text_example)\n",
    "word_to_num = {grams[x]:x for x in range(len(grams))}\n",
    "num_to_word = {x:grams[x] for x in range(len(grams))}\n",
    "num_sentence = [word_to_num[x] for x in text_example]\n",
    "print(num_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      num_sentence, \n",
    "      vocabulary_size=len(grams),\n",
    "      window_size=3,\n",
    "      negative_samples=0)\n",
    "print(len(positive_skip_grams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation above broke the results into a list of correspondences in that 3 word window. For instance, if we look up 36, we can see that it corresponds with th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_six = [x for x in positive_skip_grams if 36 in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25, 36],\n",
       " [13, 36],\n",
       " [29, 36],\n",
       " [36, 13],\n",
       " [18, 36],\n",
       " [33, 36],\n",
       " [27, 36],\n",
       " [36, 18],\n",
       " [36, 27],\n",
       " [36, 33],\n",
       " [36, 25],\n",
       " [36, 29]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirty_six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one final step before proceeding onto the final product. An additional processing step is to intentionally create \"bad\" data-points which will stand in contrast to the associations we just created. This is referred to as negative sampling. For the sake of this example, we will use the tensorflow function tf.random.log_uniform_candidate_sampler which will let us omit the correct context words when sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([11  1 14  7], shape=(4,), dtype=int64)\n",
      "['and', '18th-century', 'by', 'The']\n"
     ]
    }
   ],
   "source": [
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# Set the number of negative samples per positive context. \n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class, # class that should be sampled as 'positive'\n",
    "    num_true=1, # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns, # number of negative context words to sample\n",
    "    unique=True, # all the negative samples should be unique\n",
    "    range_max=len(grams), # pick index of the samples from [0, vocab_size]\n",
    "    seed=13, # seed for reproducibility\n",
    "    name=\"negative_sampling\" # name of this operation\n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([num_to_word[index.numpy()] for index in negative_sampling_candidates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([13  0 20  1], shape=(4,), dtype=int64)\n",
      "['been', '17th-', 'imperial', '18th-century']\n"
     ]
    }
   ],
   "source": [
    "# Get target and context words for one positive skip-gram.\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# Set the number of negative samples per positive context. \n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class, # class that should be sampled as 'positive'\n",
    "    num_true=1, # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns, # number of negative context words to sample\n",
    "    unique=True, # all the negative samples should be unique\n",
    "    range_max=len(grams), # pick index of the samples from [0, vocab_size]\n",
    "    seed=13, # seed for reproducibility\n",
    "    name=\"negative_sampling\" # name of this operation\n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([num_to_word[index.numpy()] for index in negative_sampling_candidates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([13,  0, 20,  1])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sampling_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a dimension so you can use concatenation (on the next step).\n",
    "negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
    "\n",
    "# Concat positive context word with negative sampled words.\n",
    "context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "# Label first context word as 1 (positive) followed by num_ns 0s (negative).\n",
    "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\") \n",
    "\n",
    "# Reshape target to shape (1,) and context and label to (num_ns+1,).\n",
    "target = tf.squeeze(target_word)\n",
    "context = tf.squeeze(context)\n",
    "label =  tf.squeeze(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 25\n",
      "target_word     : or\n",
      "context_indices : [36 13  0 20  1]\n",
      "context_words   : ['to,', 'been', '17th-', 'imperial', '18th-century']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {num_to_word[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "print(f\"context_words   : {[num_to_word[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have represented our variables, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the template described in the Tensorflow tutorial, we will define a function that performs all of this data transformation for us. This function is described below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[15, 7], [32, 7], [18, 22], [33, 16], [4, 9], [4, 25], [22, 4], [2, 22], [30, 25], [24, 31], [33, 34], [31, 21], [24, 33], [9, 22], [5, 29], [33, 33], [36, 26], [34, 7], [14, 12], [28, 5], [21, 13], [5, 14], [35, 24], [13, 35], [18, 6], [17, 1], [33, 16], [23, 34], [18, 29], [34, 13], [35, 2], [22, 8], [13, 20], [21, 24], [32, 27], [24, 5], [5, 24], [26, 24], [18, 26], [23, 1], [30, 12], [29, 13], [6, 23], [14, 14], [13, 11], [13, 27], [37, 12], [18, 13], [24, 37], [35, 12], [15, 4], [26, 13], [37, 26], [24, 10], [34, 35], [21, 17], [35, 18], [1, 37], [21, 11], [21, 23], [35, 22], [33, 17], [31, 12], [24, 29], [15, 19], [30, 18], [27, 13], [10, 23], [26, 31], [36, 27], [19, 17], [24, 11], [7, 21], [6, 15], [15, 31], [2, 26], [21, 29], [21, 21], [3, 17], [4, 18], [21, 32], [13, 6], [22, 24], [11, 19], [20, 16], [33, 6], [35, 10], [21, 8], [18, 1], [21, 27], [9, 6], [11, 10], [26, 13], [34, 9], [35, 9], [2, 35], [32, 35], [23, 37], [27, 30], [29, 37], [34, 6], [24, 25], [30, 22], [29, 31], [29, 6], [35, 18], [28, 6], [36, 2], [4, 14], [23, 26], [34, 16], [16, 23], [21, 13], [33, 11], [26, 9], [26, 26], [35, 17], [34, 18], [24, 26], [37, 13], [27, 12], [19, 28], [29, 15], [34, 32], [24, 14], [33, 36], [13, 37], [15, 23], [13, 4], [34, 21], [5, 4], [33, 19], [26, 1], [21, 20], [32, 26], [21, 26], [8, 25], [5, 1], [17, 5], [24, 11], [3, 6], [24, 31], [17, 35], [18, 7], [18, 13], [30, 14], [6, 17], [22, 32], [32, 22], [35, 28], [27, 25], [19, 3], [6, 27], [29, 10], [23, 11], [17, 24], [23, 32], [32, 24], [35, 32], [33, 29], [6, 24], [33, 25], [3, 17], [36, 34], [30, 36], [35, 37], [4, 19], [18, 34], [37, 34], [7, 9], [31, 9], [8, 15], [13, 14], [18, 25], [17, 23], [5, 11], [5, 15], [8, 12], [21, 18], [24, 8], [23, 35], [30, 23], [34, 22], [6, 37], [1, 4], [21, 1], [32, 15], [6, 2], [2, 33], [4, 6], [22, 6], [21, 22], [8, 24], [2, 2], [35, 2], [6, 16], [3, 27], [21, 6], [18, 37], [3, 14], [36, 9], [25, 34], [18, 21], [35, 33], [24, 23], [9, 19], [35, 21], [15, 1], [27, 7], [35, 37], [14, 3], [35, 1], [24, 34], [5, 4], [21, 1], [8, 19], [22, 19], [15, 28], [8, 17], [13, 29], [34, 26], [25, 33], [37, 29], [24, 17], [22, 2], [16, 16], [1, 21], [10, 25], [21, 31], [17, 29], [2, 6], [37, 15], [20, 32], [26, 5], [19, 37], [36, 26], [12, 16], [29, 3], [13, 9], [12, 13], [26, 5], [35, 23], [26, 24], [34, 30], [35, 31], [21, 19], [21, 18], [25, 13], [2, 24], [8, 4], [9, 2], [8, 20], [29, 11], [24, 13], [34, 6], [2, 15], [16, 10], [33, 35], [13, 9], [18, 24], [35, 22], [19, 8], [34, 24], [34, 13], [13, 15], [24, 16], [4, 8], [21, 11], [33, 11], [35, 17], [21, 1], [17, 16], [1, 24], [33, 37], [13, 8], [24, 16], [12, 22], [8, 31], [5, 11], [3, 3], [24, 26], [12, 20], [15, 35], [18, 21], [15, 12], [21, 9], [36, 35], [14, 11], [36, 10], [36, 13], [33, 21], [33, 32], [1, 10], [2, 33], [2, 29], [23, 30], [22, 36], [13, 27], [13, 12], [21, 23], [20, 35], [5, 13], [33, 24], [11, 7], [11, 4], [6, 25], [29, 35], [20, 32], [30, 27], [17, 24], [12, 30], [21, 12], [33, 6], [35, 7], [8, 36], [34, 26], [25, 27], [28, 26], [35, 6], [20, 28], [20, 6], [21, 34], [22, 12], [5, 22], [33, 33], [33, 26], [15, 14], [27, 15], [13, 15], [33, 16], [34, 4], [25, 14], [24, 19], [7, 12], [6, 28], [13, 31], [21, 37], [24, 6], [17, 20], [32, 14], [35, 5], [19, 6], [25, 31], [13, 27], [33, 30], [18, 21], [33, 34], [5, 6], [19, 27], [33, 3], [34, 21], [2, 22], [31, 17], [23, 3], [26, 6], [18, 17], [25, 1], [12, 30], [19, 18], [13, 14], [5, 6], [33, 34], [33, 30], [5, 12], [3, 24], [8, 30], [35, 29], [7, 18], [17, 26], [17, 9], [35, 34], [17, 7], [27, 4], [15, 9], [30, 33], [35, 20], [4, 12], [13, 28], [30, 36], [19, 9], [5, 22], [31, 8], [34, 2], [36, 26], [9, 2], [23, 36], [25, 30], [27, 24], [34, 35], [1, 12], [14, 15], [28, 19], [4, 21], [28, 22], [6, 19], [18, 25], [35, 19], [18, 33], [21, 19], [2, 33], [36, 22], [33, 21], [33, 21], [16, 25], [24, 30], [25, 30], [34, 8], [21, 24], [26, 34], [29, 20], [25, 11], [1, 27], [24, 26], [11, 13], [22, 9], [34, 9], [34, 29], [31, 11], [35, 7], [19, 18], [35, 21], [26, 24], [7, 25], [24, 3], [33, 12], [17, 2], [16, 5], [14, 3], [28, 4], [6, 7], [9, 8], [4, 24], [27, 20], [15, 6], [25, 8], [6, 15], [24, 3], [24, 22], [29, 2], [16, 7], [35, 12], [22, 15], [30, 10], [30, 11], [8, 24], [1, 21], [17, 19], [3, 4], [17, 26], [31, 8], [8, 29], [21, 16], [16, 29], [16, 36], [35, 37], [17, 26], [13, 8], [4, 11], [36, 18], [30, 33], [37, 30], [13, 4], [34, 37], [21, 4], [24, 10], [19, 21], [22, 36], [18, 35], [24, 34], [11, 14], [32, 21], [24, 17], [33, 4], [22, 21], [12, 15], [34, 17], [9, 26], [34, 13], [34, 7], [13, 35], [6, 15], [1, 5], [32, 37], [27, 24], [35, 11], [15, 13], [21, 29], [12, 27], [2, 35], [35, 30], [20, 33], [20, 7], [8, 18], [24, 14], [4, 17], [26, 29], [6, 25], [24, 21], [16, 28], [12, 33], [16, 13], [29, 33], [2, 20], [14, 8], [17, 32], [34, 21], [33, 34], [28, 21], [13, 6], [33, 10], [35, 22], [34, 35], [32, 6], [8, 35], [14, 5], [21, 25], [31, 7], [21, 17], [25, 12], [34, 6], [23, 21], [21, 28], [26, 21], [12, 16], [18, 3], [21, 34], [37, 35], [33, 26], [27, 16], [33, 13], [9, 24], [32, 6], [14, 6], [8, 9], [28, 13], [18, 11], [36, 33], [33, 5], [33, 34], [22, 6], [9, 32], [18, 3], [23, 18], [6, 29], [35, 24], [33, 21], [21, 26], [8, 19], [33, 16], [11, 37], [25, 29], [21, 8], [9, 33], [3, 32], [29, 5], [14, 14], [8, 12], [31, 14], [20, 28], [3, 6], [35, 30], [17, 21], [12, 25], [8, 34], [29, 34], [28, 6], [35, 6], [25, 29], [12, 33], [17, 10], [20, 12], [33, 13], [30, 1], [27, 25], [26, 7], [13, 13], [34, 3], [6, 7], [16, 33], [24, 13], [16, 12], [23, 29], [33, 2], [23, 9], [14, 5], [16, 34], [18, 9], [21, 31], [13, 35], [22, 25], [23, 11], [35, 20], [27, 4], [12, 2], [2, 26], [12, 36], [16, 17], [18, 12], [25, 28], [20, 5], [35, 7], [15, 11], [15, 35], [1, 26], [17, 29], [34, 9], [28, 22], [33, 29], [26, 23], [23, 17], [35, 34], [13, 37], [18, 36], [35, 15], [1, 1], [18, 29], [29, 34], [33, 18], [15, 18], [26, 17], [13, 31], [26, 32], [27, 8], [31, 9], [12, 32], [8, 20], [23, 23], [13, 12], [24, 34], [27, 3], [24, 26], [31, 34], [34, 37], [33, 32], [27, 24], [35, 34], [9, 10], [19, 5], [18, 30], [17, 8], [28, 24], [33, 35], [15, 33], [35, 30], [13, 34], [33, 31], [28, 3], [25, 31], [2, 16], [17, 31], [13, 35], [15, 36], [27, 22], [21, 21], [33, 16], [19, 6], [2, 8], [19, 24], [36, 27], [13, 22], [21, 26], [34, 7], [9, 8], [35, 8], [21, 36], [12, 30], [35, 18], [35, 13], [31, 24], [37, 1], [35, 35], [21, 16], [30, 3], [25, 36], [33, 26], [30, 35], [20, 2], [7, 21], [35, 22], [37, 11], [34, 18], [11, 26], [18, 25], [2, 36], [37, 21], [35, 34], [17, 8], [35, 14], [10, 25], [6, 37], [21, 4], [37, 27], [33, 20], [24, 12], [15, 26], [30, 37], [8, 2], [18, 10], [18, 34], [6, 13], [28, 3], [25, 37], [16, 12], [13, 35], [16, 36], [13, 22], [21, 35], [14, 22], [31, 12], [17, 30], [35, 24], [21, 31], [36, 32], [20, 31], [31, 25], [31, 31], [24, 29], [33, 12], [11, 19], [28, 21], [34, 15], [33, 36], [12, 16], [33, 12], [16, 12], [18, 37], [21, 19], [24, 2], [27, 3], [18, 2], [18, 26], [12, 33], [26, 19], [35, 2], [24, 33], [26, 8], [35, 10], [9, 21], [37, 31], [21, 29], [33, 8], [9, 24], [36, 25], [15, 19], [18, 36], [21, 32], [5, 31], [25, 37], [21, 1], [7, 5], [33, 16], [25, 27], [33, 14], [14, 1], [35, 18], [18, 9], [1, 11], [28, 1], [34, 1], [2, 21], [1, 14], [12, 23], [5, 3], [35, 34], [12, 22], [11, 10], [33, 4], [37, 17], [6, 23], [2, 28], [34, 13], [29, 25], [28, 24], [2, 24], [34, 22], [37, 23], [18, 21], [1, 23], [17, 36], [24, 17], [27, 17], [25, 30], [21, 19], [28, 17], [35, 36], [35, 21], [36, 26], [35, 5], [6, 1], [34, 8], [7, 28], [1, 16], [19, 10], [22, 37], [21, 17], [22, 5], [33, 33], [4, 12], [21, 9], [21, 2], [29, 31], [36, 19], [5, 23], [28, 35], [37, 30], [34, 9], [37, 5], [22, 33], [9, 9], [37, 9], [13, 33], [21, 16], [1, 23], [21, 11], [21, 11], [19, 26], [32, 35], [3, 12], [21, 32], [1, 1], [2, 12], [31, 32], [35, 21], [28, 32], [10, 34], [8, 5], [29, 35], [31, 31], [27, 33], [18, 31], [13, 33], [36, 2], [27, 30], [1, 3], [13, 31], [16, 17], [17, 13], [5, 28], [26, 18], [33, 20], [30, 7], [28, 4], [30, 33], [14, 15], [21, 34], [6, 35], [35, 21], [32, 9], [14, 24], [24, 34], [34, 13], [23, 12], [21, 26], [22, 36], [36, 29], [13, 18], [32, 31], [10, 22], [24, 36], [33, 8], [19, 34], [35, 37], [2, 32], [35, 14], [14, 27], [24, 2], [16, 20], [19, 2], [32, 8], [11, 23], [25, 30], [26, 33], [4, 7], [6, 8], [32, 2], [23, 7], [18, 7], [13, 21], [14, 14], [9, 7], [33, 24], [33, 9], [29, 3], [7, 27], [21, 2], [19, 28], [18, 30], [24, 15], [34, 19], [21, 10], [35, 13], [34, 20], [30, 4], [24, 32], [33, 15], [26, 28], [29, 13], [25, 25], [32, 24], [3, 30], [11, 4], [18, 13], [27, 6], [35, 13], [19, 1], [35, 37], [10, 18], [21, 37], [35, 34], [33, 22], [31, 24], [34, 32], [27, 4], [27, 36], [25, 19], [21, 17], [32, 37], [36, 31], [33, 32], [35, 1], [19, 6], [35, 32], [13, 25], [11, 8], [28, 31], [3, 9], [37, 35], [14, 4], [4, 17], [4, 4], [21, 4], [33, 17], [33, 2], [21, 28], [26, 8], [31, 1], [34, 23], [3, 11], [24, 23], [17, 15], [35, 25], [35, 9], [19, 28], [9, 14], [26, 29], [18, 23], [25, 7], [2, 12], [28, 10], [6, 29], [18, 34], [17, 21], [13, 27], [9, 29], [1, 19], [20, 10], [12, 27], [12, 32], [15, 10], [36, 3], [35, 15], [5, 5], [35, 3], [22, 4], [12, 20], [35, 18], [35, 26], [29, 3], [29, 35], [14, 37], [11, 15], [34, 18], [33, 36], [31, 34], [22, 37], [33, 29], [36, 34], [13, 33], [28, 6], [33, 14], [33, 30], [9, 35], [21, 31], [21, 24], [18, 14], [35, 23], [18, 9], [36, 36], [35, 13], [24, 28], [28, 16], [14, 19], [3, 6], [33, 1], [30, 34], [30, 14], [28, 34], [6, 33], [3, 5], [24, 18], [30, 27], [15, 34], [16, 30], [17, 21], [6, 30], [35, 21], [15, 23], [34, 22], [20, 2], [29, 17], [23, 14], [35, 20], [8, 12], [35, 32], [18, 33], [16, 24], [31, 18], [30, 21], [21, 18], [21, 26], [37, 9], [29, 33], [28, 2], [33, 14], [19, 17], [26, 15], [5, 27], [27, 29], [6, 22], [5, 5], [32, 28], [33, 10], [11, 1], [27, 20], [18, 35], [11, 2], [18, 32], [33, 11], [32, 34], [31, 26], [13, 36], [31, 32], [33, 24], [31, 2], [34, 13], [21, 32], [7, 3], [7, 4], [33, 15], [23, 25], [23, 34], [32, 28], [21, 24], [11, 33], [34, 35], [37, 35], [21, 35], [30, 35], [10, 30], [32, 6], [18, 7], [21, 34], [10, 33], [34, 19], [21, 24], [15, 21], [4, 3], [11, 23], [8, 2], [1, 33], [26, 17], [30, 27], [11, 21], [36, 22], [13, 16], [1, 22], [8, 6], [21, 23], [37, 15], [23, 35], [4, 29], [35, 30], [13, 13], [29, 19], [2, 12], [22, 24], [7, 31], [2, 18], [25, 9], [12, 18], [18, 19], [24, 29], [7, 2], [22, 24], [22, 36], [6, 16], [33, 33], [21, 34], [24, 3], [32, 21], [23, 32], [2, 13], [14, 23], [11, 18], [13, 26], [31, 2], [15, 22], [24, 19], [2, 22], [36, 15], [11, 16], [22, 19], [35, 18], [12, 34], [9, 8], [36, 6], [20, 12], [13, 30], [32, 37], [16, 31], [31, 18], [27, 4], [27, 21], [34, 22], [36, 5], [18, 31], [33, 36], [13, 15], [32, 8], [34, 15], [31, 19], [25, 18], [4, 19], [3, 29], [23, 5], [23, 31], [16, 30], [21, 10], [12, 10], [33, 16], [21, 34], [21, 1], [18, 13], [13, 18], [3, 24], [24, 23], [19, 16], [1, 26], [34, 32], [19, 5], [18, 17], [20, 16], [19, 17], [18, 8], [33, 5], [34, 22], [18, 35], [10, 9], [28, 16], [33, 6], [35, 9], [32, 22], [9, 11], [19, 17], [24, 30], [15, 17], [3, 9], [37, 3], [13, 34], [3, 11], [15, 5], [31, 33], [27, 8], [23, 29], [13, 20], [31, 30], [33, 34], [35, 6], [37, 15], [11, 16], [8, 8], [2, 28], [33, 9], [28, 9], [22, 20], [23, 16], [13, 36], [33, 10], [32, 28], [8, 7], [29, 36], [30, 16], [3, 28], [2, 16], [10, 9], [5, 11], [24, 11], [24, 10], [3, 37], [4, 16], [24, 22], [13, 6], [15, 28], [34, 8], [12, 22], [24, 6], [24, 23], [5, 29], [34, 20], [30, 18], [26, 2], [18, 29], [25, 2], [10, 27], [22, 28], [30, 14], [11, 37], [1, 5], [21, 34], [18, 21], [20, 17], [18, 6], [28, 36], [25, 29], [29, 18], [9, 4], [7, 12], [14, 2], [33, 33], [23, 25], [31, 8], [1, 20], [35, 24], [22, 29], [9, 7], [14, 9], [33, 35], [21, 7], [13, 18], [19, 31], [18, 7], [24, 20], [36, 24], [20, 33], [6, 11], [12, 20], [13, 18], [18, 15], [21, 7], [36, 23], [35, 29], [23, 4], [34, 28], [17, 25], [30, 23], [19, 17], [27, 32], [33, 28], [10, 20], [10, 19], [20, 33], [6, 28], [37, 20], [12, 6], [14, 5], [21, 12], [9, 4], [13, 18], [34, 23], [10, 34], [7, 18], [29, 21], [33, 27], [14, 4], [8, 21], [11, 21], [1, 5], [29, 27], [35, 28], [35, 12], [33, 15], [15, 35], [21, 35], [22, 26], [18, 12], [22, 28], [13, 34], [8, 17], [21, 29], [26, 33], [8, 2], [32, 20], [35, 15], [21, 16], [33, 4], [25, 1], [24, 19], [34, 18], [5, 22], [21, 8], [12, 25], [33, 31], [35, 18], [28, 21], [13, 15], [19, 37], [16, 5], [29, 11], [21, 15], [3, 6], [3, 37], [11, 3], [16, 20], [32, 24], [9, 7], [13, 17], [3, 8], [13, 19], [15, 25], [10, 16]], [0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "window = 3\n",
    "negative_samples = 4\n",
    "SEED = 13\n",
    "sentence = \"The Guadeloupe amazon is a hypothetical extinct species of parrot that is thought to have been endemic to the Lesser Antillean island region of Guadeloupe. Described by 17th- and 18th-century writers, it is thought to have been related to, or possibly the same as, the extant imperial amazon.\"\n",
    "text_example = sentence.split(\" \")\n",
    "grams = np.unique(text_example)\n",
    "vocab_size = len(grams)\n",
    "word_to_num = {grams[x]:x for x in range(len(grams))}\n",
    "num_to_word = {x:grams[x] for x in range(len(grams))}\n",
    "num_sentence = [word_to_num[x] for x in text_example]    \n",
    "sample_table = positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams( num_sentence,  vocabulary_size=len(grams), window_size=window, negative_samples=negative_samples)\n",
    "print(sample_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(sentence, window , negative_samples = 4 ):\n",
    "    # [1] Tokenize the sentence that is provided:\n",
    "    text_example = sentence.split(\" \")     \n",
    "    # [2] create from/to mappings using dictionary objects.\n",
    "    grams = np.unique(text_example)\n",
    "    word_to_num = {grams[x]:x for x in range(len(grams))}\n",
    "    num_to_word = {x:grams[x] for x in range(len(grams))}\n",
    "    num_sentence = [word_to_num[x] for x in text_example]          \n",
    "    # [3] Perform preprocessing step:  \n",
    "    skip_vals=tf.keras.preprocessing.sequence.skipgrams( num_sentence, vocabulary_size=len(grams), window_size=window, negative_samples=negative_samples) \n",
    "    labels = [x for x in skip_vals[1]]\n",
    "    targets = [x[0] for x in skip_vals[0] ]\n",
    "    contexts = [x[1] for x in skip_vals[0]]   \n",
    "    return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = Embedding(vocab_size, \n",
    "                                      embedding_dim,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\", )\n",
    "    self.context_embedding = Embedding(vocab_size, \n",
    "                                       embedding_dim, \n",
    "                                       input_length=num_ns+1)\n",
    "    self.dots = Dot(axes=(3,2))\n",
    "    self.flatten = Flatten()\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    we = self.target_embedding(target)\n",
    "    ce = self.context_embedding(context)\n",
    "    dots = self.dots([ce, we])\n",
    "    return self.flatten(dots) \n",
    "\n",
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (((1024,), (1024,)), (1024,)), types: ((tf.int32, tf.int32), tf.int32)>\n",
      "<PrefetchDataset shapes: (((1024,), (1024,)), (1024,)), types: ((tf.int32, tf.int32), tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(sentence,window  = 3)\n",
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4a5418fd1614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "word2vec.fit(dataset, epochs=20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.iris()\n",
    "fig = px.scatter_3d(df, x='sepal_length', y='sepal_width', z='petal_width',\n",
    "              color='species')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "species=setosa<br>sepal_length=%{x}<br>sepal_width=%{y}<br>petal_width=%{z}<extra></extra>",
         "legendgroup": "setosa",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "setosa",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          5.1,
          4.9,
          4.7,
          4.6,
          5,
          5.4,
          4.6,
          5,
          4.4,
          4.9,
          5.4,
          4.8,
          4.8,
          4.3,
          5.8,
          5.7,
          5.4,
          5.1,
          5.7,
          5.1,
          5.4,
          5.1,
          4.6,
          5.1,
          4.8,
          5,
          5,
          5.2,
          5.2,
          4.7,
          4.8,
          5.4,
          5.2,
          5.5,
          4.9,
          5,
          5.5,
          4.9,
          4.4,
          5.1,
          5,
          4.5,
          4.4,
          5,
          5.1,
          4.8,
          5.1,
          4.6,
          5.3,
          5
         ],
         "y": [
          3.5,
          3,
          3.2,
          3.1,
          3.6,
          3.9,
          3.4,
          3.4,
          2.9,
          3.1,
          3.7,
          3.4,
          3,
          3,
          4,
          4.4,
          3.9,
          3.5,
          3.8,
          3.8,
          3.4,
          3.7,
          3.6,
          3.3,
          3.4,
          3,
          3.4,
          3.5,
          3.4,
          3.2,
          3.1,
          3.4,
          4.1,
          4.2,
          3.1,
          3.2,
          3.5,
          3.1,
          3,
          3.4,
          3.5,
          2.3,
          3.2,
          3.5,
          3.8,
          3,
          3.8,
          3.2,
          3.7,
          3.3
         ],
         "z": [
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.4,
          0.3,
          0.2,
          0.2,
          0.1,
          0.2,
          0.2,
          0.1,
          0.1,
          0.2,
          0.4,
          0.4,
          0.3,
          0.3,
          0.3,
          0.2,
          0.4,
          0.2,
          0.5,
          0.2,
          0.2,
          0.4,
          0.2,
          0.2,
          0.2,
          0.2,
          0.4,
          0.1,
          0.2,
          0.1,
          0.2,
          0.2,
          0.1,
          0.2,
          0.2,
          0.3,
          0.3,
          0.2,
          0.6,
          0.4,
          0.3,
          0.2,
          0.2,
          0.2,
          0.2
         ]
        },
        {
         "hovertemplate": "species=versicolor<br>sepal_length=%{x}<br>sepal_width=%{y}<br>petal_width=%{z}<extra></extra>",
         "legendgroup": "versicolor",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "versicolor",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          7,
          6.4,
          6.9,
          5.5,
          6.5,
          5.7,
          6.3,
          4.9,
          6.6,
          5.2,
          5,
          5.9,
          6,
          6.1,
          5.6,
          6.7,
          5.6,
          5.8,
          6.2,
          5.6,
          5.9,
          6.1,
          6.3,
          6.1,
          6.4,
          6.6,
          6.8,
          6.7,
          6,
          5.7,
          5.5,
          5.5,
          5.8,
          6,
          5.4,
          6,
          6.7,
          6.3,
          5.6,
          5.5,
          5.5,
          6.1,
          5.8,
          5,
          5.6,
          5.7,
          5.7,
          6.2,
          5.1,
          5.7
         ],
         "y": [
          3.2,
          3.2,
          3.1,
          2.3,
          2.8,
          2.8,
          3.3,
          2.4,
          2.9,
          2.7,
          2,
          3,
          2.2,
          2.9,
          2.9,
          3.1,
          3,
          2.7,
          2.2,
          2.5,
          3.2,
          2.8,
          2.5,
          2.8,
          2.9,
          3,
          2.8,
          3,
          2.9,
          2.6,
          2.4,
          2.4,
          2.7,
          2.7,
          3,
          3.4,
          3.1,
          2.3,
          3,
          2.5,
          2.6,
          3,
          2.6,
          2.3,
          2.7,
          3,
          2.9,
          2.9,
          2.5,
          2.8
         ],
         "z": [
          1.4,
          1.5,
          1.5,
          1.3,
          1.5,
          1.3,
          1.6,
          1,
          1.3,
          1.4,
          1,
          1.5,
          1,
          1.4,
          1.3,
          1.4,
          1.5,
          1,
          1.5,
          1.1,
          1.8,
          1.3,
          1.5,
          1.2,
          1.3,
          1.4,
          1.4,
          1.7,
          1.5,
          1,
          1.1,
          1,
          1.2,
          1.6,
          1.5,
          1.6,
          1.5,
          1.3,
          1.3,
          1.3,
          1.2,
          1.4,
          1.2,
          1,
          1.3,
          1.2,
          1.3,
          1.3,
          1.1,
          1.3
         ]
        },
        {
         "hovertemplate": "species=virginica<br>sepal_length=%{x}<br>sepal_width=%{y}<br>petal_width=%{z}<extra></extra>",
         "legendgroup": "virginica",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "virginica",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": [
          6.3,
          5.8,
          7.1,
          6.3,
          6.5,
          7.6,
          4.9,
          7.3,
          6.7,
          7.2,
          6.5,
          6.4,
          6.8,
          5.7,
          5.8,
          6.4,
          6.5,
          7.7,
          7.7,
          6,
          6.9,
          5.6,
          7.7,
          6.3,
          6.7,
          7.2,
          6.2,
          6.1,
          6.4,
          7.2,
          7.4,
          7.9,
          6.4,
          6.3,
          6.1,
          7.7,
          6.3,
          6.4,
          6,
          6.9,
          6.7,
          6.9,
          5.8,
          6.8,
          6.7,
          6.7,
          6.3,
          6.5,
          6.2,
          5.9
         ],
         "y": [
          3.3,
          2.7,
          3,
          2.9,
          3,
          3,
          2.5,
          2.9,
          2.5,
          3.6,
          3.2,
          2.7,
          3,
          2.5,
          2.8,
          3.2,
          3,
          3.8,
          2.6,
          2.2,
          3.2,
          2.8,
          2.8,
          2.7,
          3.3,
          3.2,
          2.8,
          3,
          2.8,
          3,
          2.8,
          3.8,
          2.8,
          2.8,
          2.6,
          3,
          3.4,
          3.1,
          3,
          3.1,
          3.1,
          3.1,
          2.7,
          3.2,
          3.3,
          3,
          2.5,
          3,
          3.4,
          3
         ],
         "z": [
          2.5,
          1.9,
          2.1,
          1.8,
          2.2,
          2.1,
          1.7,
          1.8,
          1.8,
          2.5,
          2,
          1.9,
          2.1,
          2,
          2.4,
          2.3,
          1.8,
          2.2,
          2.3,
          1.5,
          2.3,
          2,
          2,
          1.8,
          2.1,
          1.8,
          1.8,
          1.8,
          2.1,
          1.6,
          1.9,
          2,
          2.2,
          1.5,
          1.4,
          2.3,
          2.4,
          1.8,
          1.8,
          2.1,
          2.4,
          2.3,
          1.9,
          2.3,
          2.5,
          2.3,
          1.9,
          2,
          2.3,
          1.8
         ]
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "species"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "sepal_length"
          }
         },
         "yaxis": {
          "title": {
           "text": "sepal_width"
          }
         },
         "zaxis": {
          "title": {
           "text": "petal_width"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"fb15a578-7d65-4fc8-adee-89ab32fb40af\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fb15a578-7d65-4fc8-adee-89ab32fb40af\")) {                    Plotly.newPlot(                        \"fb15a578-7d65-4fc8-adee-89ab32fb40af\",                        [{\"hovertemplate\": \"species=setosa<br>sepal_length=%{x}<br>sepal_width=%{y}<br>petal_width=%{z}<extra></extra>\", \"legendgroup\": \"setosa\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"setosa\", \"scene\": \"scene\", \"showlegend\": true, \"type\": \"scatter3d\", \"x\": [5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0], \"y\": [3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.1, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3], \"z\": [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2]}, {\"hovertemplate\": \"species=versicolor<br>sepal_length=%{x}<br>sepal_width=%{y}<br>petal_width=%{z}<extra></extra>\", \"legendgroup\": \"versicolor\", \"marker\": {\"color\": \"#EF553B\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"versicolor\", \"scene\": \"scene\", \"showlegend\": true, \"type\": \"scatter3d\", \"x\": [7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7], \"y\": [3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8], \"z\": [1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1.0, 1.3, 1.4, 1.0, 1.5, 1.0, 1.4, 1.3, 1.4, 1.5, 1.0, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.0, 1.1, 1.0, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1.0, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3]}, {\"hovertemplate\": \"species=virginica<br>sepal_length=%{x}<br>sepal_width=%{y}<br>petal_width=%{z}<extra></extra>\", \"legendgroup\": \"virginica\", \"marker\": {\"color\": \"#00cc96\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"virginica\", \"scene\": \"scene\", \"showlegend\": true, \"type\": \"scatter3d\", \"x\": [6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9], \"y\": [3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0], \"z\": [2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2.0, 1.9, 2.1, 2.0, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2.0, 2.0, 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2.0, 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2.0, 2.3, 1.8]}],                        {\"legend\": {\"title\": {\"text\": \"species\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"scene\": {\"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"xaxis\": {\"title\": {\"text\": \"sepal_length\"}}, \"yaxis\": {\"title\": {\"text\": \"sepal_width\"}}, \"zaxis\": {\"title\": {\"text\": \"petal_width\"}}}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fb15a578-7d65-4fc8-adee-89ab32fb40af');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.iris()\n",
    "fig = px.scatter_3d(df, x='sepal_length', y='sepal_width', z='petal_width',\n",
    "              color='species')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walks:\n",
    "\n",
    "\n",
    "\n",
    ". This based in the fact that one approach for natural language processing views the ordering of words in a manner similar to a graph since each n-gram has a set of words that follow it. Strategies that treat text this way are naturally amenable to domains where we are explicitly working on a network structure.\n",
    "\n",
    "Methods which employ node embeddings have several fundamental steps:\n",
    "1. Create a \"corpus\" of node connections using a random walk.\n",
    "2. Define a transformation on the list of node connections from **1** which groups node values that are close together with a high number, and nodes that have less of a relationship with a small number.\n",
    "3. Run a standard machine learning method on the new set of factors from step **2**.\n",
    "\n",
    "Here we explore the first step in this process: The random choosing of node values in the graph structure. This step is taken to approximate the connections each node has as a list. This carries two advantages:\n",
    "1. Each node similarity measure has both local (direct) connections, and also expresses higher order connections (indirect). This is known as **Expressivity**.\n",
    "2. All node pairs don't need to be encoded; we don't have to worry about coding the zero probabilities. This is **Efficiency**.\n",
    "\n",
    "We will discuss some of the methods used for random walks in the sections below in reference to the paper where they were originally discussed.\n",
    "\n",
    "### DeepWalk Method\n",
    "\n",
    "*DeepWalk: Online Learning of Social Representations* uses short random walks. In this case, we define a random walk starting at vertex $V_i$ as $W_i$. This random walk is a stochastic process composed of random variables $W_i^k$ where k denotes the step in the sequence of each random walk.\n",
    "\n",
    "For this method, a stream of random walks is created. This method has the added advantage of being easy to parallelize and is also less sensitive to changes in the underlying graph than using a larger length random walk.\n",
    "\n",
    "The implementation of the DeepWalk method is used in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources:\n",
    "\n",
    "* [ An Illustrated Explanation of Using SkipGram To Encode The Structure of A Graph  ](  https://medium.com/@_init_/an-illustrated-explanation-of-using-skipgram-to-encode-the-structure-of-a-graph-deepwalk-6220e304d71b#:~:text=DeepWalk%20is%20an%20algorithm%20that,community%20structure%20of%20the%20graph.&text=However%2C%20SkipGram%20is%20an%20algorithm,used%20to%20create%20word%20embeddings)\n",
    "* [ Word2Vec Tutorial - The Skip-Gram Model ]( http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
    "* [DeepWalk: Online Learning of Social Representations](http://www.perozzi.net/publications/14_kdd_deepwalk.pdf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
