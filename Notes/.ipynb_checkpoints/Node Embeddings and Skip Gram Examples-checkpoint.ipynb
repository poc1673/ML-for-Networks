{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Embeddings and Skip Gram Examples\n",
    "\n",
    "**Purpose:** - to explore the node embedding methods used for methods such as Word2Vec.\n",
    "\n",
    "**Introduction-** one of the key methods used in node classification actually draws inspiration from natural language processing. This based in the fact that one approach for natural language processing views the ordering of words in a manner similar to a graph since each n-gram has a set of words that follow it. Strategies that treat text this way are naturally amenable to domains where we are explicitly working on a network structure.\n",
    "\n",
    "Methods which employ node embeddings have several fundamental steps:\n",
    "1. Create a \"corpus\" of node connections using a random walk.\n",
    "2. Define a transformation on the list of node connections from **1** which groups node values that are close together with a high number, and nodes that have less of a relationship with a small number.\n",
    "3. Run a standard machine learning method on the new set of factors from step **2**.\n",
    "\n",
    "\n",
    "## Random Walks:\n",
    "\n",
    "Here we explore the first step in this process: The random choosing of node values in the graph structure. This step is taken to approximate the connections each node has as a list. This carries two advantages:\n",
    "1. Each node similarity measure has both local (direct) connections, and also expresses higher order connections (indirect). This is known as **Expressivity**.\n",
    "2. All node pairs don't need to be encoded; we don't have to worry about coding the zero probabilities. This is **Efficiency**.\n",
    "\n",
    "We will discuss some of the methods used for random walks in the sections below in reference to the paper where they were originally discussed.\n",
    "\n",
    "### DeepWalk Method\n",
    "\n",
    "*DeepWalk: Online Learning of Social Representations* uses short random walks. In this case, we define a random walk starting at vertex $V_i$ as $W_i$. This random walk is a stochastic process composed of random variables $W_i^k$ where k denotes the step in the sequence of each random walk.\n",
    "\n",
    "For this method, a stream of random walks is created. This method has the added advantage of being easy to parallelize and is also less sensitive to changes in the underlying graph than using a larger length random walk.\n",
    "\n",
    "The implementation of the DeepWalk method is used in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, os, random\n",
    "from IPython.core.debugger import set_trace\n",
    "np.random.seed(13)\n",
    "dat = pd.read_csv(\"../Data/soc-sign-bitcoinalpha.csv\", names = [\"SOURCE\", \"TARGET\", \"RATING\", \"TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3286"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(dat.SOURCE)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3754"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(dat.TARGET) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from_vals = pd.unique(dat.SOURCE)\n",
    "\n",
    "#a = dat.TARGET[dat.SOURCE == from_vals[1]]\n",
    "# Generate list comprehension using from values as a key; to values are saved as a list.\n",
    "#node_lists = {x:dat.TARGET[dat.SOURCE == x].values for x in from_vals  }\n",
    "\n",
    "# Generate a step by selecting one value randomly from the list of \"to\" nodes:\n",
    "def gen_step(key_val,dict_vals):\n",
    "   # print(dict_vals[key_val])\n",
    "    return( dict_vals[key_val][random.randint(0,len(dict_vals[key_val])-1)]  )\n",
    "\n",
    "def gen_walk(key_val,dict_vals,steps):\n",
    "    walk_vals = [key_val]    \n",
    "    for i in range(0,steps-1):\n",
    "        walk_vals.append(gen_step(walk_vals[-1],dict_vals) )\n",
    "    return(walk_vals)\n",
    "\n",
    "def RW_DeepWalk( orig_nodes, to_vals, walk_length=3):\n",
    "    from_vals = pd.unique(orig_nodes)\n",
    "    node_lists = {x:to_vals[orig_nodes == x].values for x in from_vals}\n",
    "    start_nodes = [* node_lists]\n",
    "    start_nodes=[x for x in start_nodes if x in node_lists.keys()]\n",
    "    walks = {x:gen_walk(key_val= x,dict_vals = node_lists,steps=walk_length) for x in start_nodes}\n",
    "    return(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to sort these values, we need to make a full list of \"from\" and \"to\" for the random walk. This is performed in the script below:\n",
    "# Identify values in \"to\" column that might not be in the from column:\n",
    "f = dat.SOURCE\n",
    "t = dat.TARGET\n",
    "unique_t = [x for x in pd.unique(t) if not(x in pd.unique(f))]\n",
    "x_over = dat[dat['TARGET'].isin( unique_t)]\n",
    "# Add entries from the \"to\" column to the from column; add corresponding entries from the \"from\" column. This way, we include mappings of nodes in the \"to\" column as part of the random walk.\n",
    "full_from = f.append(x_over.TARGET)\n",
    "full_to = t.append(x_over.SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_walk = RW_DeepWalk( full_from, full_to, walk_length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of one of the arrays obtained using a random walk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 22, 191, 59, 26, 166, 2995, 55, 1946, 119]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_walk[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of the random walk method provides a way of representing the network that can be performed quickly. This method is also simple to parallelize. Finally, this method and the speed it can be used allows for a quick way to update calculations due to changes in the graph structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node2vec Method\n",
    "\n",
    "The paper \"Scalable Feature Learning for Networks\" uses a separate method called a \"biased random walk\". \n",
    "\n",
    "\n",
    "One of the points made in the paper is the type of sampling strategies that can be used to try to approximate the neighborhood around some node (this is denoted as $N_s$ in the paper). There are two extremes for sampling strategies that can be employed:\n",
    "\n",
    "* Breadh-first sampling (BFS) - The neighborhood is restricted to nodes which are immediate neighbors of the source node. For this, we define the neighborhood **only** with directly adjacent nodes.\n",
    "* Depth-first sampling (DFS) - The neighborhood consists of nodes sequentially sampled at increasing distances from the source node. This is represented in the random walk algorithm that was shown in the last section.\n",
    "\n",
    "\n",
    "A biased random walk as expressed by the authors is an interpolation between the two strategies mentioned above.\n",
    "\n",
    "Let $u$ be the source node, and $l$ be the length of the random walk. Let $c_i$ be the $i$th node in the walk where $c_0 = u$. Then, $c_i$ is generated as follows:\n",
    "\n",
    "$$ P(c_i = x | c_{i-1} =v) = \\frac{\\pi_{v,x} }{Z} $$ and 0 otherwise.\n",
    "\n",
    "Where $\\pi_{v,x}$ is the unnormalized transition probability between nodes $v$ and $x$, and $Z$ is some constant that normalizes the probability between the two nodes. This is very similar to the formulation that was desecribed earlier for DeepWalk. \n",
    "\n",
    "The simplest way to introduce bias to the random walks is to sample based onthe static edge weights: $w_{v,x} = \\pi_{v,x} $. In the case of an unweighted graph like the one used in the example above, $w_{v,x} =1$. \n",
    "\n",
    "We will define a $2$nd order random walk with parameters $p,q$. We will set the unnoramlized transition probability to $\\pi_{v,x} = \\alpha_{p,q}(t,x)*w_{v,x}$ where \\alpha_{p,q}(t,x) is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\alpha_{p,q}(t,x) =\n",
    "    \\begin{cases}\n",
    "      \\frac{1}{p} & \\text{if $d_{t,x}=0$ }\\\\\n",
    "     1 & \\text{if $d_{t,x}=1$ }\\\\\n",
    "      \\frac{1}{q}  & \\text{if $d_{t,x}=2$ }\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "\n",
    "Where $d_{t,x}$ defines the shortest path distance between nodes $t$ and $x$ Also note that $d_{t,x} \\in \\{0,1,2\\}$\n",
    "\n",
    "Changing parameters $p$ and $q$ will impact the speed that the walk leaves the current neighborhood. In the example provided in the paper, the authors consider a process which as just transitioned to node *v* from node *t*. It has three potential choices for its next step:\n",
    "\n",
    "* Transition back to *t* with the bias of $\\alpha_{t,v} = \\frac{1}{p}$ being applied.\n",
    "* Transition to a shared node with a bias of 1 being applied.\n",
    "* Transition to an unshared node with a bias of $\\alpha_{t,v} = \\frac{1}{q}$ being applied.\n",
    "\n",
    "Then - a lower q-value and higher p-value will increase the likelihood of leaving the initial neighborhood of *t*. At the extreme, you would get the original random walk implementation described above by letting $p =1$ and $q=1$.\n",
    "\n",
    "A higher q value will decrease the likelihood of the current step moving to a node that neig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-13-841def726807>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-841def726807>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the node values into three different groups\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply weightings to each edge to change the likelihood of leaving the neighborhood.\n",
    " \n",
    "# A biased random walk as described in the node2vec paper. The p and q values are defaulted to 1 which will make this the same as the RW_DeepWalk paper described earlier.\n",
    "def RW_Biased( orig_nodes, to_vals, walk_length=3,p = 1,q =1):\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_vals = pd.unique(full_from)\n",
    "node_lists = {x:full_to[full_from == x].values for x in from_vals}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "cur_node = gen_step(430,node_lists)\n",
    "prev_node_list = node_lists[cur_node]\n",
    "cur_node_list = node_lists[430]\n",
    "\n",
    "shared_nodes = list(set(prev_node_list) & set(cur_node_list))\n",
    "unshared_nodes = list(set(prev_node_list) ^ set(cur_node_list))\n",
    "prev_node = 430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12,\n",
       " 13,\n",
       " 26,\n",
       " 34,\n",
       " 36,\n",
       " 59,\n",
       " 81,\n",
       " 116,\n",
       " 125,\n",
       " 229,\n",
       " 247,\n",
       " 336,\n",
       " 413,\n",
       " 430,\n",
       " 459,\n",
       " 817,\n",
       " 831,\n",
       " 1055,\n",
       " 1067,\n",
       " 1575,\n",
       " 1864,\n",
       " 3230,\n",
       " 7509,\n",
       " 7595}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   13,   59,  247,  831,  817, 1055, 7595, 7509])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_nodes = [* node_lists]\n",
    "start_nodes=[x for x in start_nodes if x in node_lists.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. [NRL Totorial Part 1](http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part1-embeddings.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
