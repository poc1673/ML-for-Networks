{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Embeddings and Skip Gram Examples\n",
    "\n",
    "**Purpose:** - To explore embedding methods used in label prediction for social networks. This will include a short exposition on the relation of natural language processing to network analysis.\n",
    "\n",
    "**Introduction-** Node embedding methods are a commonly used method for node classification for social networks. This modeling method employs a feature engineering method call skip-gram modeling to represent the relationship of each node in the network in $N$ dimensional vector space. This vector can be thought of as a low dimensional representation of each node. Nodes which are more closely associated with one another will be clustered more closely together in our vector representation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Root in natural language processing\n",
    "\n",
    "This method draws from research in natural language processing where we try to anticipate nearby words based on a corpus used to build the model. Consider the following example system:\n",
    "> The Guadeloupe amazon is a hypothetical extinct species of parrot that is thought to have been endemic to the Lesser Antillean island region of Guadeloupe. Described by 17th- and 18th-century writers, it is thought to have been related to, or possibly the same as, the extant imperial amazon. \n",
    "\n",
    "In natural language processing, one strategy we can use is to define a window of size $w$. These will be used to define an association of words. For example, if we use a window of 3 words we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Guadeloupe', 'amazon'],\n",
       " ['Guadeloupe', 'amazon', 'is'],\n",
       " ['amazon', 'is', 'a'],\n",
       " ['is', 'a', 'hypothetical'],\n",
       " ['a', 'hypothetical', 'extinct'],\n",
       " ['hypothetical', 'extinct', 'species'],\n",
       " ['extinct', 'species', 'of'],\n",
       " ['species', 'of', 'parrot'],\n",
       " ['of', 'parrot', 'that'],\n",
       " ['parrot', 'that', 'is'],\n",
       " ['that', 'is', 'thought'],\n",
       " ['is', 'thought', 'to'],\n",
       " ['thought', 'to', 'have'],\n",
       " ['to', 'have', 'been'],\n",
       " ['have', 'been', 'endemic'],\n",
       " ['been', 'endemic', 'to'],\n",
       " ['endemic', 'to', 'the'],\n",
       " ['to', 'the', 'Lesser'],\n",
       " ['the', 'Lesser', 'Antillean'],\n",
       " ['Lesser', 'Antillean', 'island'],\n",
       " ['Antillean', 'island', 'region'],\n",
       " ['island', 'region', 'of'],\n",
       " ['region', 'of', 'Guadeloupe.'],\n",
       " ['of', 'Guadeloupe.', 'Described'],\n",
       " ['Guadeloupe.', 'Described', 'by'],\n",
       " ['Described', 'by', '17th-'],\n",
       " ['by', '17th-', 'and'],\n",
       " ['17th-', 'and', '18th-century'],\n",
       " ['and', '18th-century', 'writers,'],\n",
       " ['18th-century', 'writers,', 'it'],\n",
       " ['writers,', 'it', 'is'],\n",
       " ['it', 'is', 'thought'],\n",
       " ['is', 'thought', 'to'],\n",
       " ['thought', 'to', 'have'],\n",
       " ['to', 'have', 'been'],\n",
       " ['have', 'been', 'related'],\n",
       " ['been', 'related', 'to,'],\n",
       " ['related', 'to,', 'or'],\n",
       " ['to,', 'or', 'possibly'],\n",
       " ['or', 'possibly', 'the'],\n",
       " ['possibly', 'the', 'same'],\n",
       " ['the', 'same', 'as,'],\n",
       " ['same', 'as,', 'the'],\n",
       " ['as,', 'the', 'extant'],\n",
       " ['the', 'extant', 'imperial'],\n",
       " ['extant', 'imperial', 'amazon.']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "text_example = \"The Guadeloupe amazon is a hypothetical extinct species of parrot that is thought to have been endemic to the Lesser Antillean island region of Guadeloupe. Described by 17th- and 18th-century writers, it is thought to have been related to, or possibly the same as, the extant imperial amazon.\"\n",
    "text_example = text_example.split(\" \")\n",
    "[[text_example[0+x],text_example[1+x],text_example[2+x]] for x in range(len(text_example)-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walks:\n",
    "\n",
    "\n",
    "\n",
    ". This based in the fact that one approach for natural language processing views the ordering of words in a manner similar to a graph since each n-gram has a set of words that follow it. Strategies that treat text this way are naturally amenable to domains where we are explicitly working on a network structure.\n",
    "\n",
    "Methods which employ node embeddings have several fundamental steps:\n",
    "1. Create a \"corpus\" of node connections using a random walk.\n",
    "2. Define a transformation on the list of node connections from **1** which groups node values that are close together with a high number, and nodes that have less of a relationship with a small number.\n",
    "3. Run a standard machine learning method on the new set of factors from step **2**.\n",
    "\n",
    "Here we explore the first step in this process: The random choosing of node values in the graph structure. This step is taken to approximate the connections each node has as a list. This carries two advantages:\n",
    "1. Each node similarity measure has both local (direct) connections, and also expresses higher order connections (indirect). This is known as **Expressivity**.\n",
    "2. All node pairs don't need to be encoded; we don't have to worry about coding the zero probabilities. This is **Efficiency**.\n",
    "\n",
    "We will discuss some of the methods used for random walks in the sections below in reference to the paper where they were originally discussed.\n",
    "\n",
    "### DeepWalk Method\n",
    "\n",
    "*DeepWalk: Online Learning of Social Representations* uses short random walks. In this case, we define a random walk starting at vertex $V_i$ as $W_i$. This random walk is a stochastic process composed of random variables $W_i^k$ where k denotes the step in the sequence of each random walk.\n",
    "\n",
    "For this method, a stream of random walks is created. This method has the added advantage of being easy to parallelize and is also less sensitive to changes in the underlying graph than using a larger length random walk.\n",
    "\n",
    "The implementation of the DeepWalk method is used in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources:\n",
    "\n",
    "* [ An Illustrated Explanation of Using SkipGram To Encode The Structure of A Graph  ](  https://medium.com/@_init_/an-illustrated-explanation-of-using-skipgram-to-encode-the-structure-of-a-graph-deepwalk-6220e304d71b#:~:text=DeepWalk%20is%20an%20algorithm%20that,community%20structure%20of%20the%20graph.&text=However%2C%20SkipGram%20is%20an%20algorithm,used%20to%20create%20word%20embeddings)\n",
    "* [ Word2Vec Tutorial - The Skip-Gram Model ]( http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
    "* [DeepWalk: Online Learning of Social Representations](http://www.perozzi.net/publications/14_kdd_deepwalk.pdf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
